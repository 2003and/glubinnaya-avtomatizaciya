{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing and importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 13:13:18.966942: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-21 13:13:19.119468: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-21 13:13:19.119500: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-21 13:13:19.120507: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-21 13:13:19.192902: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-21 13:13:19.195215: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-21 13:13:20.392283: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%pip install -q tensorflow numpy protobuf==3.20.3\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from random import randint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initModel(num_of_epoch=100):\n",
    "    # Specifying inputs and outputs\n",
    "    inp = [[1, 0], [-1, 1], [-1, 1], [1, 1]]\n",
    "    inputTensor = tf.constant(inp, shape=(len(inp), 2))\n",
    "    oup = [[1], [-1], [1], [-1]]\n",
    "    outputTensor = tf.constant(oup, shape=(len(oup), 1))\n",
    "    # Initializing the model\n",
    "    model = tf.keras.Sequential()\n",
    "    # Adding input layers and activation functions\n",
    "    model.add(tf.keras.layers.Dense(units=2, input_shape=(2,), activation='sigmoid'))\n",
    "    model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "    # Hidden layer is added automatically during learning\n",
    "    # Compiling the model (no shit)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(0.1), loss='mean_squared_error')\n",
    "    # The process of learning\n",
    "    model.fit(inputTensor, outputTensor, epochs=num_of_epoch, shuffle=True, callbacks=[LossHistoryCallback()])\n",
    "    return model\n",
    "\n",
    "class LossHistoryCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        loss = logs['loss']\n",
    "\n",
    "def generateInputs(num):\n",
    "    return [[randint(-10, 10), randint(-10, 10)] for _ in range(num)]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 1.1973\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1359\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0881\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0533\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0292\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0130\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0025\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9957\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9912\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9881\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9857\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9838\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9821\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9805\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9788\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9770\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9750\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9729\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9707\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9683\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9659\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9633\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9608\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9582\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9556\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9531\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9506\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9480\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9453\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9425\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9394\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9361\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9326\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9289\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9250\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9210\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9170\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9129\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9089\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9048\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9007\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8965\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8922\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.8878\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8832\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8786\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8739\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8692\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8646\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8600\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8556\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8513\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8470\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8429\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8389\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8350\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8311\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8274\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8237\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8202\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8168\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8135\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8103\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8072\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8043\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8015\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7988\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7963\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7940\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7918\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7897\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7878\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7859\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7842\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7826\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7811\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7797\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7783\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7770\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7758\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7747\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7736\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7726\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7716\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7707\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7699\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7691\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7683\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7676\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7669\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7663\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7657\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7652\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7647\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7642\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7637\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7633\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7628\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7624\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7621\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7617\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7614\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7610\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7607\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7604\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7602\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7599\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7596\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7594\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7592\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7590\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7587\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7585\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7584\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7582\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7580\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7578\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7577\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7575\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7573\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7572\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7571\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7569\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7568\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7567\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7565\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7564\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7563\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7562\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7561\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7560\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7559\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7558\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7557\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7556\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7555\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7554\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7553\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7553\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7552\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7551\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7550\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7550\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7549\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7548\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7548\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7547\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7546\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7546\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7545\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "lossHistory = []\n",
    "\n",
    "model = initModel(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "[0.91732395]\n",
      "[0.00304161]\n",
      "[0.9216649]\n",
      "[0.00427053]\n"
     ]
    }
   ],
   "source": [
    "test = np.array([[-1,-1],[-1,1],[1,-1],[1,1]])\n",
    "predictions = model.predict(test)\n",
    "for i in predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
